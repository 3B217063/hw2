import requests
from bs4 import BeautifulSoup
import json

url = "https://www.books.com.tw/web/sys_saletopb/books/19?attribute=30"

try:
    response = requests.get(url, timeout=10)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, "lxml")

    # ğŸ¯ æŠ“æ’è¡Œæ¦œä¸»è¦æ›¸ç±é …ç›®
    books = soup.select("div.mod_a li.item, div.mod_b li.item, li.top_item")
    result = []

    for idx, book in enumerate(books[:20], start=1):
        try:
            # ğŸŸ© æ›¸å
            title_tag = book.select_one("h4 a")
            title = title_tag.get_text(strip=True) if title_tag else "N/A"

            # ğŸŸ¦ åƒ¹æ ¼å€å¡Šï¼ˆæŠ˜æ‰£èˆ‡å¯¦éš›åƒ¹ï¼‰
            price_block = book.select_one("li.price_a")

            if price_block:
                # æŠ˜æ‰£ (ä¾‹å¦‚ "79")
                discount_tag = price_block.select_one("strong b")
                discount = discount_tag.get_text(strip=True) if discount_tag else "N/A"

                # å¯¦éš›åƒ¹æ ¼ï¼ˆæœ€å¾Œä¸€å€‹ <b> æ˜¯åƒ¹æ ¼ï¼‰
                all_b_tags = price_block.select("b")
                if len(all_b_tags) >= 2:
                    real_price = all_b_tags[-1].get_text(strip=True)
                else:
                    real_price = "N/A"

                price = f"{discount}æŠ˜ NT${real_price}"
            else:
                price = "N/A"

            result.append({
                "rank": str(idx),
                "title": title,
                "price": price
            })

        except Exception as e:
            print(f"âš ï¸ ç¬¬ {idx} æœ¬æ›¸è§£æå¤±æ•—ï¼š{e}")
            continue

    print(json.dumps(result, indent=4, ensure_ascii=False))

except requests.exceptions.RequestException as e:
    print(f"âŒ ç„¡æ³•å–å¾—ç¶²é ï¼š{e}")
except Exception as e:
    print(f"âŒ ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š{e}")
